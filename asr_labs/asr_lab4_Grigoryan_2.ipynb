{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/Speech_pro/blob/main/asr_labs/asr_lab4_Grigoryan_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcyxmRJGqlY"
      },
      "source": [
        "# Практика №4\n",
        "\n",
        "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbO_rrWGq7j"
      },
      "source": [
        "### Bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzJyomV1JaLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9509c9a7-dbc6-4820-dd47-a9c97ee5e75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchaudio) (4.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TROAsHTXHWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b206b4-14a8-44c9-b9e4-0cff3e52b166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
            "To: /content/lab4.zip\n",
            "100% 2.77M/2.77M [00:00<00:00, 276MB/s]\n",
            "/content/lab4\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
        "\n",
        "!unzip -q lab4.zip\n",
        "!rm -rf lab4.zip sample_data\n",
        "%cd lab4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4wcCtkIH2dn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from utils import TextTransform\n",
        "from utils import cer\n",
        "from utils import wer\n",
        "\n",
        "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
        "from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer\n",
        "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
        "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
        "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
        "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
        "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHKuY8HnAC4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e43aff8-44f2-4ed0-ef83-e7cacf1f60aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 11:12:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaESUZiHJgfN"
      },
      "outputs": [],
      "source": [
        "train_audio_transforms = torch.nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
        "                                                              n_fft=400,\n",
        "                                                              hop_length=160,\n",
        "                                                              n_mels=80)\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "#-----------------------------TODO №2-----------------------------------\n",
        "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
        "#-----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0])\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True, text_transform_another = None):\n",
        "    arg_maxes = torch.argmax(output, dim=2)\n",
        "    decodes = []\n",
        "    targets = []\n",
        "    for i, args in enumerate(arg_maxes):\n",
        "        decode = []\n",
        "        if text_transform_another:\n",
        "          targets.append(text_transform_another.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "        else:\n",
        "          targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "        for j, index in enumerate(args):\n",
        "            if index != blank_label:\n",
        "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                    continue\n",
        "                decode.append(index.item())\n",
        "        if text_transform_another:\n",
        "          decodes.append(text_transform_another.int_to_text(decode))\n",
        "        else:\n",
        "          decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OqoVLnrJsCV"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=80,\n",
        "        output_size=29,\n",
        "        conv2d_filters=32,\n",
        "        attention_dim=240,\n",
        "        attention_heads=8,\n",
        "        feedforward_dim=512,\n",
        "        num_layers=8,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        \n",
        "        self.conv_in = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.conv_out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(conv2d_filters * (input_size // 4), attention_dim),\n",
        "            PositionalEncoding(attention_dim, 0.1),\n",
        "        )\n",
        "        positionwise_layer = PositionwiseFeedForward\n",
        "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
        "        self.encoder_layer = repeat(\n",
        "            num_layers,\n",
        "            lambda lnum: EncoderLayer(\n",
        "                attention_dim,\n",
        "                MultiHeadedAttention(\n",
        "                    attention_heads, attention_dim, dropout\n",
        "                ),\n",
        "                positionwise_layer(*positionwise_layer_args),\n",
        "                dropout,\n",
        "                normalize_before=True,\n",
        "                concat_after=False,\n",
        "            ),\n",
        "        )\n",
        "        self.after_norm = LayerNorm(attention_dim)\n",
        "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
        "\n",
        "    def forward(self, x, ilens):\n",
        "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
        "        x = self.conv_in(x)\n",
        "        b, c, t, f = x.size()\n",
        "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
        "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
        "        x, _ = self.encoder_layer(x, masks)\n",
        "        x = self.after_norm(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhbOKdLLbXHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3457fa-4284-4e43-8da0-9f3acdd3b1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 200, 29])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(2, 800, 80)\n",
        "model = TransformerModel()\n",
        "output = model(x, [800, 90])\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2p_8IjeKkqq"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
        "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if batch_idx % 500 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(spectrograms),\n",
        "                data_len,\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item(),\n",
        "                scheduler.get_last_lr()[0]))\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, decode=True):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
        "            \n",
        "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "            input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            if decode:\n",
        "              decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "              for j in range(len(decoded_preds)):\n",
        "                  test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                  test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "    if decode:\n",
        "        avg_cer = sum(test_cer)/len(test_cer)\n",
        "        avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "        print(f\"Test set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n\")\n",
        "        return test_loss, avg_cer, avg_wer\n",
        "    else:\n",
        "        print(f\"Average loss: {test_loss:.4f}\\n\")\n",
        "        return test_loss, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzEbtsB1LKsh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    \n",
        "    hparams = {\n",
        "        \"input_size\": 80,\n",
        "        \"output_size\": 29,\n",
        "        \"conv2d_filters\": 32,\n",
        "        \"attention_dim\": 320,\n",
        "        \"attention_heads\": 8,\n",
        "        \"feedforward_dim\": 1024,\n",
        "        \"num_layers\":10,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=test_batch_size,\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        hparams['input_size'],\n",
        "        hparams['output_size'],\n",
        "        hparams['conv2d_filters'],\n",
        "        hparams['attention_dim'],\n",
        "        hparams['attention_heads'],\n",
        "        hparams['feedforward_dim'],\n",
        "        hparams['num_layers'],\n",
        "        hparams['dropout']).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    df_res = pd.DataFrame(columns=['Train loss', 'Test loss', 'Test average CER', 'Test average WER'])\n",
        "    i = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        !date\n",
        "        train_loss = train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        test_loss, test_avg_cer, test_avg_wer = test(model, device, test_loader, criterion, epoch, decode=not(epoch % 5))\n",
        "        df_res.loc[i] = train_loss, test_loss, test_avg_cer, test_avg_wer\n",
        "        i += 1\n",
        "    return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d0c05bd5ebcb4adb91b7b798abffd42b",
            "e598f3ceccfd4e47979b3ba7719daf6b",
            "018338b779454fbb9b55fbeae7012581",
            "af3d6301d7c946d8b210723f0bc2beb0",
            "bb0c3b492b5c474785119dfd33423431",
            "c5ebe3c17ca7437993c5ee6152ef9854",
            "ff57d95663164e9c8273903096bc6cdf",
            "c78a734c3e63497d9ff9fed97a0b3721",
            "dc5440b2f9994dfe9619272d25ba8e7e",
            "15e9936cccc447da8ad55d94e27b6659",
            "4ccda3b45d914dafb27f844f7f661f49",
            "79b26e6d033a46c798ea6d4f729ed23f",
            "b0d3af37838f44f489451d98590420f7",
            "84717d2759b04537881224b7844bf226",
            "472d826027014b35b32cba608dbb6149",
            "724327d7fdb243ad9302835bb9400708",
            "2cad6d96a16a4243aff7a32ea6c6d090",
            "f94301a9157f441b89d7695664fac07f",
            "20d5f37e42d64744a1d70bcdbd540921",
            "a5799d33e0a7461dacc41af1285bf98a",
            "6b4b7db92dc844278461ce6a7422a74d",
            "2575a9d25558465185c31bc9c9fb994c"
          ]
        },
        "id": "eExZLsUiLeXk",
        "outputId": "7511a9be-e31b-4ebc-e900-91e61c5875d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c05bd5ebcb4adb91b7b798abffd42b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79b26e6d033a46c798ea6d4f729ed23f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=320, out_features=29, bias=True)\n",
            ")\n",
            "Num Model Parameters 10913277\n",
            "Tue Jun 14 11:18:27 UTC 2022\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 4.717116\tLR: 0.000040\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.723638\tLR: 0.000096\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.801434\tLR: 0.000152\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.567359\tLR: 0.000208\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.315697\tLR: 0.000264\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.364256\tLR: 0.000320\n",
            "\n",
            "evaluating...\n",
            "Average loss: 2.1849\n",
            "\n",
            "Tue Jun 14 11:26:22 UTC 2022\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 2.063535\tLR: 0.000360\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 2.242276\tLR: 0.000416\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 2.091914\tLR: 0.000472\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 2.171904\tLR: 0.000528\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 2.014167\tLR: 0.000584\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.972482\tLR: 0.000640\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.9228\n",
            "\n",
            "Tue Jun 14 11:34:03 UTC 2022\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 2.032520\tLR: 0.000680\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.988569\tLR: 0.000736\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.953999\tLR: 0.000792\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.753450\tLR: 0.000848\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.886749\tLR: 0.000904\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.957591\tLR: 0.000961\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.5831\n",
            "\n",
            "Tue Jun 14 11:41:39 UTC 2022\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.835672\tLR: 0.001000\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.584560\tLR: 0.000975\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.626930\tLR: 0.000950\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.761285\tLR: 0.000925\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.551810\tLR: 0.000900\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.549830\tLR: 0.000875\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.2760\n",
            "\n",
            "Tue Jun 14 11:49:15 UTC 2022\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 1.593595\tLR: 0.000857\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.360626\tLR: 0.000832\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.365445\tLR: 0.000807\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.206670\tLR: 0.000782\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.636836\tLR: 0.000757\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.258194\tLR: 0.000732\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.0753, Average CER: 0.272473 Average WER: 0.7463\n",
            "\n",
            "Tue Jun 14 12:02:22 UTC 2022\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 1.161559\tLR: 0.000714\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 1.409109\tLR: 0.000689\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.348652\tLR: 0.000664\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 1.406097\tLR: 0.000639\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 1.242448\tLR: 0.000614\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 1.200376\tLR: 0.000589\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.9552\n",
            "\n",
            "Tue Jun 14 12:09:58 UTC 2022\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 1.363777\tLR: 0.000571\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 1.370677\tLR: 0.000546\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.305537\tLR: 0.000521\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 1.004312\tLR: 0.000496\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 1.178258\tLR: 0.000471\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 1.217478\tLR: 0.000446\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.8756\n",
            "\n",
            "Tue Jun 14 12:17:35 UTC 2022\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 1.010105\tLR: 0.000428\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 1.183530\tLR: 0.000403\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.357598\tLR: 0.000378\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 1.011127\tLR: 0.000353\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 1.041882\tLR: 0.000328\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 1.165248\tLR: 0.000303\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.7887\n",
            "\n",
            "Tue Jun 14 12:25:12 UTC 2022\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.952408\tLR: 0.000286\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.982399\tLR: 0.000261\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.971869\tLR: 0.000236\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.998437\tLR: 0.000211\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 1.053114\tLR: 0.000186\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 1.164019\tLR: 0.000160\n",
            "\n",
            "evaluating...\n",
            "Average loss: 0.7411\n",
            "\n",
            "Tue Jun 14 12:32:55 UTC 2022\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.965195\tLR: 0.000143\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.873012\tLR: 0.000118\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 1.046979\tLR: 0.000093\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 1.018402\tLR: 0.000068\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.890460\tLR: 0.000043\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.885999\tLR: 0.000018\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.7119, Average CER: 0.185658 Average WER: 0.5663\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 10\n",
        "test_batch_size = 7\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "res_df = main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)\n",
        "res_df.to_csv('res_df_0') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rVMKQ5zXw2iu",
        "outputId": "c04be01d-b393-4503-f53f-3f73c4582688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Train loss  Test loss  Test average CER  Test average WER\n",
              "0    2.278426   2.184866               NaN               NaN\n",
              "1    2.150522   1.922782               NaN               NaN\n",
              "2    1.711543   1.583076               NaN               NaN\n",
              "3    1.625872   1.276021               NaN               NaN\n",
              "4    1.247701   1.075308          0.272473          0.746305\n",
              "5    1.230747   0.955163               NaN               NaN\n",
              "6    1.098825   0.875584               NaN               NaN\n",
              "7    1.137020   0.788737               NaN               NaN\n",
              "8    0.913470   0.741123               NaN               NaN\n",
              "9    1.009547   0.711878          0.185658          0.566295"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-351f48c0-b163-4c02-af15-7060bec3c42e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train loss</th>\n",
              "      <th>Test loss</th>\n",
              "      <th>Test average CER</th>\n",
              "      <th>Test average WER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.278426</td>\n",
              "      <td>2.184866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.150522</td>\n",
              "      <td>1.922782</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.711543</td>\n",
              "      <td>1.583076</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.625872</td>\n",
              "      <td>1.276021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.247701</td>\n",
              "      <td>1.075308</td>\n",
              "      <td>0.272473</td>\n",
              "      <td>0.746305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.230747</td>\n",
              "      <td>0.955163</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.098825</td>\n",
              "      <td>0.875584</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.137020</td>\n",
              "      <td>0.788737</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.913470</td>\n",
              "      <td>0.741123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.009547</td>\n",
              "      <td>0.711878</td>\n",
              "      <td>0.185658</td>\n",
              "      <td>0.566295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-351f48c0-b163-4c02-af15-7060bec3c42e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-351f48c0-b163-4c02-af15-7060bec3c42e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-351f48c0-b163-4c02-af15-7060bec3c42e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mby39YVqZadd"
      },
      "source": [
        "### <b>Задание №1</b> (5 баллов):\n",
        "На данный момент практически все E2E SOTA решения используют [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Пример обучения BPE токенайзера можно найти в [link](https://github.com/google/sentencepiece/tree/master/python). Главное правильно обернуть его в наш класс TextTransformBPE. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFS3PNxEAUiK"
      },
      "source": [
        "### **Ответ**:\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2Y8PDmL2MBX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQE-_bCc2KL7"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNbiW919e2le"
      },
      "outputs": [],
      "source": [
        "class TextTransformBPE:\n",
        "    def __init__(self, train_text, vocab_size = 1000):\n",
        "        \"\"\" Обучение BPE модели на 2000 юнитов\"\"\"\n",
        "        spm.SentencePieceTrainer.train(input=train_text, model_prefix='m', vocab_size=vocab_size,  model_type='bpe')\n",
        "        self.sp_bpe = spm.SentencePieceProcessor( )\n",
        "        self.sp_bpe.load('m.model')\n",
        "        \n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
        "        int_sequence =self.encode_as_ids(text)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
        "        string = self.sp_bpe.decode(list(map(int, labels)))\n",
        "        return string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GSoMX18lLGF"
      },
      "source": [
        "### небольшая переделка функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD2HJbg_FeuI"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data\n",
        "        spectrograms, labels = spectrograms[:, :, :, :max(input_lengths)].to(device), labels.to(\n",
        "            device)  # (batch, 1, feat_dim, time)\n",
        "        spectrograms = spectrograms.squeeze(1).transpose(1, 2)  # (batch, time, feat_dim,)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1)  # (time, batch, n_class)\n",
        "        input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if batch_idx % 500 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(spectrograms),\n",
        "                data_len,\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item(),\n",
        "                scheduler.get_last_lr()[0]))\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, decode=True, output_size=28):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            spectrograms = spectrograms.squeeze(1).transpose(1, 2)  # (batch time, feat_dim,)\n",
        "\n",
        "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1)  # (time, batch, n_class)\n",
        "            input_lengths = [x // 4 for x in input_lengths]\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            if decode:\n",
        "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths,\n",
        "                                                               blank_label=output_size,\n",
        "                                                               text_transform_another=text_transform_bpe)\n",
        "                for j in range(len(decoded_preds)):\n",
        "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "    if decode:\n",
        "        avg_cer = sum(test_cer) / len(test_cer)\n",
        "        avg_wer = sum(test_wer) / len(test_wer)\n",
        "\n",
        "        print(f\"Test set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n\")\n",
        "        return test_loss, avg_cer, avg_wer\n",
        "\n",
        "    else:\n",
        "        print(f\"Average loss: {test_loss:.4f}\\n\")\n",
        "        return test_loss, None, None\n",
        "\n",
        "\n",
        "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
        "         train_url=\"train-clean-100\", test_url=\"test-clean\", output_size=1000):\n",
        "    hparams = {\n",
        "        \"input_size\": 80,\n",
        "        \"output_size\": output_size + 1,\n",
        "        \"conv2d_filters\": 32,\n",
        "        \"attention_dim\": 320,\n",
        "        \"attention_heads\": 8,\n",
        "        \"feedforward_dim\": 1024,\n",
        "        \"num_layers\": 1,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                   batch_size=hparams['batch_size'],\n",
        "                                   shuffle=True,\n",
        "                                   collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                   **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                  batch_size=test_batch_size,\n",
        "                                  shuffle=False,\n",
        "                                  collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                  **kwargs)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        hparams['input_size'],\n",
        "        hparams['output_size'],\n",
        "        hparams['conv2d_filters'],\n",
        "        hparams['attention_dim'],\n",
        "        hparams['attention_heads'],\n",
        "        hparams['feedforward_dim'],\n",
        "        hparams['num_layers'],\n",
        "        hparams['dropout']).to(device)\n",
        "\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = torch.nn.CTCLoss(blank=output_size, zero_infinity=False).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'],\n",
        "                                              steps_per_epoch=int(len(train_loader)),\n",
        "                                              epochs=hparams['epochs'],\n",
        "                                              anneal_strategy='linear')\n",
        "    df_res = pd.DataFrame(columns=['Train loss', 'Test loss', 'Test average CER', 'Test average WER'])\n",
        "    i = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        !date\n",
        "        train_loss = train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        test_loss, test_avg_cer, test_avg_wer = test(model, device, test_loader, criterion, epoch,\n",
        "                                                     decode=not (epoch % 2), output_size=output_size)\n",
        "        df_res.loc[i] = train_loss, test_loss, test_avg_cer, test_avg_wer\n",
        "        i += 1\n",
        "    return df_res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### end"
      ],
      "metadata": {
        "id": "IiTALV230enx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdzW-drBpsN",
        "outputId": "50617e71-b6b3-4acf-9034-52988070c853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Model Parameters 1605513\n",
            "Tue Jun 14 12:46:28 UTC 2022\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 11.438374\tLR: 0.000040\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.897568\tLR: 0.000096\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.810388\tLR: 0.000152\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.701447\tLR: 0.000208\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.601564\tLR: 0.000264\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.562345\tLR: 0.000320\n",
            "\n",
            "evaluating...\n",
            "Average loss: 2.4488\n",
            "\n",
            "Tue Jun 14 12:52:11 UTC 2022\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 2.600880\tLR: 0.000360\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 2.432020\tLR: 0.000416\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 2.279716\tLR: 0.000472\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 2.420394\tLR: 0.000528\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 2.406399\tLR: 0.000584\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 2.312163\tLR: 0.000640\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.1808, Average CER: 0.489335 Average WER: 0.7046\n",
            "\n",
            "Tue Jun 14 13:11:05 UTC 2022\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 2.286155\tLR: 0.000680\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 2.249075\tLR: 0.000736\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 2.238974\tLR: 0.000792\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 2.168707\tLR: 0.000848\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 2.123001\tLR: 0.000904\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 2.220439\tLR: 0.000961\n",
            "\n",
            "evaluating...\n",
            "Average loss: 2.0742\n",
            "\n",
            "Tue Jun 14 13:16:47 UTC 2022\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 2.163620\tLR: 0.001000\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 2.100343\tLR: 0.000975\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 2.172491\tLR: 0.000950\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 2.110089\tLR: 0.000925\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 2.144797\tLR: 0.000900\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 2.086307\tLR: 0.000875\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 2.0075, Average CER: 0.456146 Average WER: 0.6680\n",
            "\n",
            "Tue Jun 14 13:36:35 UTC 2022\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 2.057869\tLR: 0.000857\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 2.193938\tLR: 0.000832\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 2.217876\tLR: 0.000807\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 2.122023\tLR: 0.000782\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 2.222322\tLR: 0.000757\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 2.117391\tLR: 0.000732\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.9658\n",
            "\n",
            "Tue Jun 14 13:42:13 UTC 2022\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 2.082809\tLR: 0.000714\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 2.182173\tLR: 0.000689\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 2.087566\tLR: 0.000664\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 2.123153\tLR: 0.000639\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 2.054165\tLR: 0.000614\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 2.031142\tLR: 0.000589\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.9249, Average CER: 0.440505 Average WER: 0.6478\n",
            "\n",
            "Tue Jun 14 14:02:16 UTC 2022\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 2.008669\tLR: 0.000571\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 2.004749\tLR: 0.000546\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.845825\tLR: 0.000521\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 1.972780\tLR: 0.000496\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 2.101728\tLR: 0.000471\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 1.936996\tLR: 0.000446\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.9012\n",
            "\n",
            "Tue Jun 14 14:07:55 UTC 2022\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 1.878139\tLR: 0.000428\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.112645\tLR: 0.000403\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.981068\tLR: 0.000378\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 1.912337\tLR: 0.000353\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.074612\tLR: 0.000328\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.037681\tLR: 0.000303\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.8639, Average CER: 0.433843 Average WER: 0.6340\n",
            "\n",
            "Tue Jun 14 14:27:57 UTC 2022\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 1.966539\tLR: 0.000286\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.015130\tLR: 0.000261\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.171413\tLR: 0.000236\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.006339\tLR: 0.000211\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 1.880963\tLR: 0.000186\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 1.953817\tLR: 0.000160\n",
            "\n",
            "evaluating...\n",
            "Average loss: 1.8280\n",
            "\n",
            "Tue Jun 14 14:33:34 UTC 2022\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.130068\tLR: 0.000143\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.041991\tLR: 0.000118\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.014816\tLR: 0.000093\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 1.934289\tLR: 0.000068\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.025471\tLR: 0.000043\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.106410\tLR: 0.000018\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 1.8149, Average CER: 0.425486 Average WER: 0.6233\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 1000\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 10\n",
        "test_batch_size = 7\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "text_transform_bpe = TextTransformBPE(train_text='train_clean_100_text_clean.txt', vocab_size=vocab_size)\n",
        "df_res_bpe = main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set,\n",
        "                  output_size=vocab_size)\n",
        "df_res_bpe.to_csv('df_res_bpe_0')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_res_bpe"
      ],
      "metadata": {
        "id": "IG6CmBdYw0GA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "08c9d532-5b3d-4902-9b41-c1d81b9337a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Train loss  Test loss  Test average CER  Test average WER\n",
              "0    2.603715   2.448839               NaN               NaN\n",
              "1    2.207538   2.180819          0.489335          0.704559\n",
              "2    2.132896   2.074214               NaN               NaN\n",
              "3    2.161153   2.007470          0.456146          0.667964\n",
              "4    2.042144   1.965822               NaN               NaN\n",
              "5    2.151035   1.924880          0.440505          0.647797\n",
              "6    2.033674   1.901240               NaN               NaN\n",
              "7    2.054268   1.863881          0.433843          0.634029\n",
              "8    1.923200   1.828038               NaN               NaN\n",
              "9    2.060679   1.814915          0.425486          0.623336"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26da7e27-fc48-40e6-9f7b-8e877b221111\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train loss</th>\n",
              "      <th>Test loss</th>\n",
              "      <th>Test average CER</th>\n",
              "      <th>Test average WER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.603715</td>\n",
              "      <td>2.448839</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.207538</td>\n",
              "      <td>2.180819</td>\n",
              "      <td>0.489335</td>\n",
              "      <td>0.704559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.132896</td>\n",
              "      <td>2.074214</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.161153</td>\n",
              "      <td>2.007470</td>\n",
              "      <td>0.456146</td>\n",
              "      <td>0.667964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.042144</td>\n",
              "      <td>1.965822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.151035</td>\n",
              "      <td>1.924880</td>\n",
              "      <td>0.440505</td>\n",
              "      <td>0.647797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.033674</td>\n",
              "      <td>1.901240</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.054268</td>\n",
              "      <td>1.863881</td>\n",
              "      <td>0.433843</td>\n",
              "      <td>0.634029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.923200</td>\n",
              "      <td>1.828038</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.060679</td>\n",
              "      <td>1.814915</td>\n",
              "      <td>0.425486</td>\n",
              "      <td>0.623336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26da7e27-fc48-40e6-9f7b-8e877b221111')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26da7e27-fc48-40e6-9f7b-8e877b221111 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26da7e27-fc48-40e6-9f7b-8e877b221111');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV48Q7HqZsAD"
      },
      "source": [
        "### <b>Задание №2</b> (5 баллов):\n",
        "Импровизация по улучшению качества распознавания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1OBVhLgATV_"
      },
      "source": [
        "### **Ответ**:\n",
        "..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "asr_lab4_Grigoryan_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0c05bd5ebcb4adb91b7b798abffd42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e598f3ceccfd4e47979b3ba7719daf6b",
              "IPY_MODEL_018338b779454fbb9b55fbeae7012581",
              "IPY_MODEL_af3d6301d7c946d8b210723f0bc2beb0"
            ],
            "layout": "IPY_MODEL_bb0c3b492b5c474785119dfd33423431"
          }
        },
        "e598f3ceccfd4e47979b3ba7719daf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ebe3c17ca7437993c5ee6152ef9854",
            "placeholder": "​",
            "style": "IPY_MODEL_ff57d95663164e9c8273903096bc6cdf",
            "value": "100%"
          }
        },
        "018338b779454fbb9b55fbeae7012581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c78a734c3e63497d9ff9fed97a0b3721",
            "max": 6387309499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc5440b2f9994dfe9619272d25ba8e7e",
            "value": 6387309499
          }
        },
        "af3d6301d7c946d8b210723f0bc2beb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e9936cccc447da8ad55d94e27b6659",
            "placeholder": "​",
            "style": "IPY_MODEL_4ccda3b45d914dafb27f844f7f661f49",
            "value": " 5.95G/5.95G [04:02&lt;00:00, 25.8MB/s]"
          }
        },
        "bb0c3b492b5c474785119dfd33423431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ebe3c17ca7437993c5ee6152ef9854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff57d95663164e9c8273903096bc6cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78a734c3e63497d9ff9fed97a0b3721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5440b2f9994dfe9619272d25ba8e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15e9936cccc447da8ad55d94e27b6659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ccda3b45d914dafb27f844f7f661f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79b26e6d033a46c798ea6d4f729ed23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0d3af37838f44f489451d98590420f7",
              "IPY_MODEL_84717d2759b04537881224b7844bf226",
              "IPY_MODEL_472d826027014b35b32cba608dbb6149"
            ],
            "layout": "IPY_MODEL_724327d7fdb243ad9302835bb9400708"
          }
        },
        "b0d3af37838f44f489451d98590420f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cad6d96a16a4243aff7a32ea6c6d090",
            "placeholder": "​",
            "style": "IPY_MODEL_f94301a9157f441b89d7695664fac07f",
            "value": "100%"
          }
        },
        "84717d2759b04537881224b7844bf226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d5f37e42d64744a1d70bcdbd540921",
            "max": 346663984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5799d33e0a7461dacc41af1285bf98a",
            "value": 346663984
          }
        },
        "472d826027014b35b32cba608dbb6149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4b7db92dc844278461ce6a7422a74d",
            "placeholder": "​",
            "style": "IPY_MODEL_2575a9d25558465185c31bc9c9fb994c",
            "value": " 331M/331M [00:14&lt;00:00, 26.4MB/s]"
          }
        },
        "724327d7fdb243ad9302835bb9400708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cad6d96a16a4243aff7a32ea6c6d090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94301a9157f441b89d7695664fac07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d5f37e42d64744a1d70bcdbd540921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5799d33e0a7461dacc41af1285bf98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b4b7db92dc844278461ce6a7422a74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2575a9d25558465185c31bc9c9fb994c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}